---
pubDate: 2025-12-22
---

##### [AWS Launches ECS Express Mode to Simplify Containerised Application Deployment by Matt Saunders](https://www.infoq.com/news/2025/12/aws-ecs-express-mode/)
##### [Prompt caching: 10x cheaper LLM tokens, but how? | ngrok blog by ngrok](https://ngrok.com/blog/prompt-caching/)
##### [Create and update Apache Iceberg tables with partitions in the AWS Glue Data Catalog using the AWS SDK and AWS CloudFormation](https://aws.amazon.com/blogs/big-data/create-and-update-apache-iceberg-tables-with-partitions-in-the-aws-glue-data-catalog-using-the-aws-sdk-and-aws-cloudformation/)
##### [APACHE SPARK OPTIMISATIONS by Guna Chandra Durgapu](https://blog.flipkart.tech/apache-spark-optimisations-c3464f71bd38)
##### [Column Storage for the AI Era by Julien Le Dem](https://sympathetic.ink/2025/12/11/Column-Storage-for-the-AI-era.html)
##### [Agent Engineering: A New Discipline by LangChain](https://blog.langchain.com/agent-engineering-a-new-discipline/)

- Agent engineering is the iterative process of refining non-deterministic LLM systems into reliable production experiences. It is a cyclical process: build, test, ship, observe, refine, repeat.

##### [Getting into public speaking - James Brooks](https://james.brooks.page/blog/getting-into-public-speaking)
##### [Skills vs Dynamic MCP Loadouts by Armin Ronacher](https://lucumr.pocoo.org/2025/12/13/skills-vs-mcp/)

- You still
declare tools ahead of time in the system message, but they are not injected
into the conversation when the initial system message is emitted.  Instead they
appear at a later point.  The tool definitions however still have to be static
for the entire conversation, as far as I know.  So the tools that could exist
are defined when the conversation starts.  The way Anthropic discovers the tools
is purely by regex search.

##### [Why your mock breaks later | Ned Batchelder by @nedbat@hachyderm.io](https://nedbatchelder.com/blog/202511/why_your_mock_breaks_later.html?featured_on=pythonbytes)
##### [Introducing AWS Glue 5.1 for Apache Spark | AWS Big Data Blog](https://aws.amazon.com/blogs/big-data/introducing-aws-glue-5-1-for-apache-spark/)
##### [Context Engineering: How RAG, agents, and memory make LLMs actually useful](https://about.datnguyen.de/blog/internal/context-engineering-modern-llm-ecosystem/?ref=blef.fr)

- This dual-memory approach mirrors human cognition:

Short-term Memory (Redis): Like working memory, it holds the current conversation context. Fast access, automatic expiration
Long-term Memory (Vector Store): Persistent knowledge that grows over time. Important patterns and learnings are embedded and searchable
