---
pubDate: 2025-02-09
---

##### [Scale Out Batch Inference with Ray](https://www.infoq.com/presentations/batch-ray/)
##### [Systematically Improving RAG Applications - Jason Liu by Jason Liu](https://jxnl.co/writing/2025/01/24/systematically-improving-rag-applications/)

- 4 Re-Rankers¶ Instead of (or in addition to) fine-tuning a bi-encoder (embedding model), you might fine-tune a cross-encoder or re-ranker that scores each candidate chunk directly. Re-rankers can be slower but often yield higher precision. Typically, you do a quick vector search, then run re-ranking on the top K results.

##### [Emerging Patterns in Building GenAI Products](https://martinfowler.com/articles/gen-ai-patterns/)

- Self evaluation: Self-evaluation lets LLMs self-assess and enhance
        their own responses. Although some LLMs can do this better than others, there
        is a critical risk with this approach. If the model’s internal self-assessment
        process is flawed, it may produce outputs that appear more confident or refined
        than they truly are, leading to reinforcement of errors or biases in subsequent
        evaluations. While self-evaluation exists as a technique, we strongly recommend
        exploring other strategies.
- LLM as a judge: The output of the LLM is evaluated  by scoring it with
        another model, which can either be a more capable LLM or a specialized
        Small Language Model (SLM). While this approach involves evaluating with
        an LLM, using a different LLM helps address some of the issues of self-evaluation.
        Since the likelihood of both models sharing the same errors or biases is low,
        this technique has become a popular choice for automating the evaluation process
- Human evaluation: Vibe checking is a technique to evaluate if
        the LLM responses match the desired tone, style, and intent. It is an
        informal way to assess if the model “gets it” and responds in a way that
        feels right for the situation. In this technique, humans manually write
        prompts and evaluate the responses. While challenging to scale, it’s the
        most effective method for checking qualitative elements that automated
        methods typically miss.
- However, embeddings are not ideal for structured or relational data, where exact 
        matching or traditional database queries are more appropriate. Tasks such as 
        finding exact matches, performing numerical comparisons, or querying relationships 
        are better suited for SQL and traditional databases than embeddings and vector stores.

##### [Why Most Machine Learning Projects Fail to Reach Production and How to Beat the Odds](https://www.infoq.com/presentations/ml-pitfalls/)