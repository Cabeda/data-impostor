---
pubDate: 2026-01-06
---

##### [10 Predictions for Data Infrastructure in 2026](https://columnar.tech/blog/2026-predictions/)
##### [My LLM coding workflow going into 2026 by Addy Osmani](https://addyosmani.com/blog/ai-coding-workflow/)

- the first step is brainstorming a detailed specification with the AI
- The key point is to avoid huge leaps. By iterating in small loops, we greatly reduce the chance of catastrophic errors and we can course-correct quickly. LLMs excel at quick, contained tasks - use that to your advantage.
- think Claude Skills have potential because they turn what used to be fragile repeated prompting into something durable and reusable by packaging instructions, scripts, and domain specific expertise into modular capabilities that tools can automatically apply when a request matches the Skill
- automated tests, do code reviews - both manual and AI-assiste
- No matter how much AI I use, I remain the accountable engineer.
- Frequent commits are your save points - they let you undo AI missteps and understand changes.
- spin up a fresh git worktree for a new feature or sub-project. This lets me run multiple AI coding sessions in parallel on the same repo without them interfering, and I can later merge the changes
- Use your CI/CD, linters, and code review bots - AI will work best in an environment that catches mistakes automatically.
- one of my goals is to bolster the quality gates around AI code contribution: more tests, more monitoring, perhaps even AI-on-AI code reviews. It might sound paradoxical (AIs reviewing AIs), but Iâ€™ve seen it catch things one model missed.
- Treat every AI coding session as a learning opportunity - the more you know, the more the AI can help you, creating a virtuous cycle.
- Dunning-Kruger on steroids (it may seem like you built something great, until it falls apart

##### [Claude Code On-The-Go](https://granda.org/en/2026/01/02/claude-code-on-the-go/)