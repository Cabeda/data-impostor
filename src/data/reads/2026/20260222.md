---
pubDate: 2026-02-22
---

##### [Bruteforcing the Bitwarden master password I forgor](https://compilercrim.es/forgor/)
##### [The AI Vampire by Steve Yegge](https://steve-yegge.medium.com/the-ai-vampire-eda6e4f07163)
##### [Introduction to PostgreSQL Indexes](https://dlt.github.io/blog/posts/introduction-to-postgresql-indexes/)

- Although it gracefully handles hash conflicts, it works better for even distribution of hash values and is most suited to unique or mostly unique data
- Nodes in BRIN indexes store the minimum and maximum values of a range of values present in the page referred by the index. This makes the index more compact and cache friendly, but restricts the use cases for it.
- Generalized inverted index is appropriate for when you want to search for an item in composite data, such as finding a word in a blob of text, an item in an array or an object in a JSON

##### [Your agents need runbooks, not bigger context windows by Ben Lorica 罗瑞卡](https://gradientflow.substack.com/p/the-missing-layer-in-todays-agent)

- Context File System (CFS). You might also hear this more broadly categorized as an Operational Skill Store. This architecture separates the expensive reasoning of a large language model from the actual storage of operational knowledge. It mirrors the way a mature engineering team works.

##### [Lance table format explained simply](https://tontinton.com/posts/lance/)
##### [Context Management for Deep Agents by LangChain Accounts](https://www.blog.langchain.com/context-management-for-deepagents/)

- Context compression refers to techniques that reduce the volume of information in an agent's working memory while preserving the details relevant to completing the task.
- Offloading large tool results: We offload large tool responses to the filesystem whenever they occur.
- Offloading large tool inputs: When the context size crosses a threshold, we offload old write/edit arguments from tool calls to the filesystem.
- Summarization: When the context size crosses the threshold, and there is no more context eligible for offloading, we perform a summarization step to compress the message history.

##### [Inside OpenAI’s in-house data agent](https://openai.com/index/inside-our-in-house-data-agent/)
##### [Performance Tips Using Postgres and pgvector | Crunchy Data Blog](https://www.crunchydata.com/blog/pgvector-performance-for-developers)

- Have enough RAM to build new indexes. Building indexes with larger lists requires higher settings for maintenance_work_mem — if you do not have the enough memory you’ll get an error. When building the lists = 2000 index above, the the maintenance_work_mem required 1.3GB of RAM.

##### [Demystifying evals for AI agents](https://www.anthropic.com/engineering/demystifying-evals-for-ai-agents)

- The agent shouldn’t be able to easily “cheat” the eval. Tasks and graders should be designed so that passing genuinely requires solving the problem rather than exploiting unintended loopholes.
- Like the Swiss Cheese Model from safety engineering, no single evaluation layer catches every issue. With multiple methods combined, failures that slip through one layer are caught by another.
- The patterns vary by agent type, but the fundamentals described here are constant. Start early and don’t wait for the perfect suite. Source realistic tasks from the failures you see. Define unambiguous, robust success criteria. Design graders thoughtfully and combine multiple types. Make sure the problems are hard enough for the model. Iterate on the evaluations to improve their signal-to-noise ratio. Read the transcripts!
